{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.479726800Z",
     "start_time": "2025-03-03T14:11:03.234710400Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.552677400Z",
     "start_time": "2025-03-03T14:11:03.249034400Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import array\n",
    "from random import random\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB#57\n",
    "from sklearn.naive_bayes import GaussianNB#52\n",
    "from sklearn.naive_bayes import MultinomialNB#56\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovering Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.553831900Z",
     "start_time": "2025-03-03T14:11:03.270723Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提取指定文件 Label 列中的唯一值并排序\n",
    "def target_name(name):\n",
    "    df = pd.read_csv(name,usecols=[\"Label\"])\n",
    "    target_names=sorted(list(df[\"Label\"].unique()))\n",
    "    return target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.570312500Z",
     "start_time": "2025-03-03T14:11:03.276099Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters of machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.572312800Z",
     "start_time": "2025-03-03T14:11:03.288263900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 定义了一个字典 ml_list，其中包含了多种机器学习模型的实例化对象。\n",
    "# 代码中使用了 scikit-learn 库中的多个分类模型，并设置了不同的超参数。\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# 修改分类器列表，使用 OvA 策略\n",
    "ml_list = {\n",
    "    \"OvA_SVM\": OneVsRestClassifier(SVC(C=10, gamma=1, probability=True)),\n",
    "    \"OvA_GB\": OneVsRestClassifier(GradientBoostingClassifier(learning_rate=0.001, subsample=0.1, n_estimators=500, max_depth=10)),\n",
    "    \"OvA_LR\": OneVsRestClassifier(LogisticRegression(max_iter=1000)),  # 示例：逻辑回归\n",
    "    \"OvA_LDA\": OneVsRestClassifier(LinearDiscriminantAnalysis()),      # 示例：线性判别分析\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation Algorithm notmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.573305800Z",
     "start_time": "2025-03-03T14:11:03.311910900Z"
    }
   },
   "outputs": [],
   "source": [
    "altime=0\n",
    "#def most_frequent(List): \n",
    "#    return max(set(List), key = List.count) \n",
    "\n",
    "\n",
    "# 找出列表中出现频率最高的元素。如果有多个元素具有相同的最高频率，则随机返回其中一个\n",
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    occurence_count={k: v for k, v in sorted(occurence_count.items(), key=lambda item: item[1],reverse=True)}\n",
    "    big=list(occurence_count.values())\n",
    "    big=big.count(big[0])\n",
    "    return list(occurence_count.keys())[np.random.randint(big)]\n",
    "\n",
    "# 将列表 a 分成 n 个大致相等的部分\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "# 找出 df 中具有重复 \"dominant MAC\" 的异常值，并返回这些异常值的列表\n",
    "def create_exception(df): \n",
    "    exception_list=[]\n",
    "    dominant_mac=[]\n",
    "    for i in df['aggregated'].unique():\n",
    "        k=df[df['aggregated']==i]\n",
    "        for ii in ['MAC']:\n",
    "            hist = {}\n",
    "            for x in k[ii].values:\n",
    "                hist[x] = hist.get(x, 0) + 1\n",
    "            hist=dict(sorted(hist.items(), key=lambda item: item[1],reverse=True))\n",
    "            temp=next(iter(hist))\n",
    "            if temp not in dominant_mac:\n",
    "                dominant_mac.append(temp)\n",
    "            else:\n",
    "                exception_list.append(temp)\n",
    "    return exception_list\n",
    "\n",
    "\n",
    "\n",
    "# 将 m_test 和 predict 合并，生成一个新的分类结果 aggregated。如果 mixed 为 True，则使用混合方法处理异常值\n",
    "def merged(m_test,predict,step,mixed):\n",
    "    second=time.time()\n",
    "    mac_test=[]\n",
    "    for q in m_test.index:\n",
    "        mac_test.append(m_test[q])\n",
    "\n",
    "    d_list=sorted(list(m_test.unique()))\n",
    "    devices={}\n",
    "    for q in d_list:\n",
    "        devices[q]=[]    \n",
    "\n",
    "\n",
    "    new_y=[0]*len(m_test)\n",
    "\n",
    "    for q,qq in enumerate (mac_test):\n",
    "        devices[qq].append(q)\n",
    "    for q in devices:\n",
    "        a = [devices[q][j:j + step] for j in range(0, len(devices[q]), step)]  \n",
    "        for qq in a:\n",
    "            step_list=[]\n",
    "            for qqq in qq:\n",
    "                step_list.append(predict[qqq])\n",
    "            add=most_frequent(list(step_list))\n",
    "            for qqq in qq:\n",
    "                new_y[qqq]=add\n",
    "    results=pd.DataFrame(m_test)\n",
    "    results[\"aggregated\"]=new_y\n",
    "    results[\"normal\"]=predict\n",
    "    \n",
    "    #MIXED METHOD\n",
    "    if mixed:\n",
    "        exception=create_exception(results)\n",
    "        for q in exception:\n",
    "            results.loc[results.MAC == q, 'aggregated'] = results['normal']\n",
    "\n",
    "    return results[\"aggregated\"].values,time.time()-second\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.591517900Z",
     "start_time": "2025-03-03T14:11:03.334618700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算和记录分类模型的性能指标，包括准确率（accuracy）、召回率（recall）、精确率（precision）、\n",
    "# F1 分数（f1-score）、平衡准确率（balanced accuracy）、Cohen's Kappa 系数等。\n",
    "# 使用 classification_report 生成分类报告，并累加存储为 DataFrame\n",
    "def score(altime,train_time,test_time,predict,y_test,class_based_results,i,cv,dname,ii):\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    f1=[]\n",
    "    accuracy=[]\n",
    "    total_time=[]\n",
    "    kappa=[]\n",
    "    accuracy_b=[]\n",
    "    \n",
    "    rc=sklearn.metrics.recall_score(y_test, predict,average= \"macro\")\n",
    "    pr=sklearn.metrics.precision_score(y_test, predict,average= \"macro\")\n",
    "    f_1=sklearn.metrics.f1_score(y_test, predict,average= \"macro\")        \n",
    "    report = classification_report(y_test, predict, target_names=target_names,output_dict=True)\n",
    "    cr = pd.DataFrame(report).transpose()\n",
    "    if class_based_results.empty:\n",
    "        class_based_results =cr\n",
    "    else:\n",
    "        class_based_results = class_based_results.add(cr, fill_value=0)\n",
    "    precision.append(float(pr))\n",
    "    recall.append(float(rc))\n",
    "    f1.append(float(f_1))\n",
    "    accuracy_b.append(balanced_accuracy_score( y_test,predict))\n",
    "    accuracy.append(accuracy_score(y_test, predict))\n",
    "\n",
    "    kappa.append(round(float(sklearn.metrics.cohen_kappa_score(y_test, predict, \n",
    "    labels=None, weights=None, sample_weight=None)),15))\n",
    "    print ('%-15s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-8s %-5s %-8s %-8s%-8s%-8s' % (dname,i,cv,ii[0:6],str(round(np.mean(accuracy),2)),str(round(np.mean(accuracy_b),2)),\n",
    "        str(round(np.mean(precision),2)), str(round(np.mean(recall),2)),str(round(np.mean(f1),4)), \n",
    "        str(round(np.mean(kappa),2)),str(round(np.mean(train_time),2)),str(round(np.mean(test_time),2)),str(round(np.mean(test_time)+np.mean(train_time),2)),str(round(np.mean(altime),2))))\n",
    "    lines=(str(dname)+\",\"+str(i)+\",\"+str(cv)+\",\"+str(ii)+\",\"+str(round(np.mean(accuracy),15))+\",\"+str(round(np.mean(accuracy_b),15))+\",\"+str(round(np.mean(precision),15))+\",\"+ str(round(np.mean(recall),15))+\",\"+str(round(np.mean(f1),15))+\",\"+str(round(np.mean(kappa),15))+\",\"+str(round(np.mean(train_time),15))+\",\"+str(round(np.mean(test_time),15))+\",\"+str(altime)+\"\\n\")\n",
    "    return lines,class_based_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.591517900Z",
     "start_time": "2025-03-03T14:11:03.349558400Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop1, loop2: 训练数据和测试数据的文件路径。\n",
    "# output_csv: 用于记录结果的 CSV 文件路径。\n",
    "# cols: 需要读取的列。\n",
    "# step: 分组的大小（用于 merged 函数）。\n",
    "# mixed: 是否使用混合方法（用于 merged 函数）。\n",
    "# dname: 数据集名称。\n",
    "def ML(loop1,loop2,output_csv,cols,step,mixed,dname):\n",
    "\n",
    "    ths = open(output_csv, \"w\")\n",
    "    ths.write(\"Dataset,T,CV,ML algorithm,Acc,b_Acc,Precision, Recall , F1-score, kappa ,tra-Time,test-Time,Al-Time\\n\")\n",
    "    \n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    \n",
    "    for ii in ml_list:\n",
    "        print ('%-15s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-8s %-5s %-8s %-8s%-8s%-8s'%\n",
    "               (\"Dataset\",\"T\",\"CV\",\"ML alg\",\"Acc\",\"b_Acc\",\"Prec\", \"Rec\" , \"F1\", \"kap\" ,\"tra-T\",\"test-T\",\"total\",\"al-time\"))\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        cv=0\n",
    "        if ii in [\"GB\",\"SVM\"]: #for slow algorithms.\n",
    "            repetition=10\n",
    "        else:\n",
    "            repetition=10\n",
    "        if ii in [\"MLP\"]: #for slow algorithms.\n",
    "            repetition=10\n",
    "\n",
    "        for i in range(repetition):\n",
    "\n",
    "\n",
    "\n",
    "            #TRAIN\n",
    "            df = pd.read_csv(loop1,usecols=cols)\n",
    "            try:df=df.replace({\"Protocol\": Protocol})\n",
    "            except:pass\n",
    "            m_train=df[\"MAC\"]\n",
    "            del df[\"MAC\"]\n",
    "            X_train =df[df.columns[0:-1]]\n",
    "            X_train=np.array(X_train)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y_train=df[df.columns[-1]].cat.codes  \n",
    "\n",
    "            #TEST\n",
    "            df = pd.read_csv(loop2,usecols=cols)\n",
    "            try:df=df.replace({\"Protocol\": Protocol})\n",
    "            except:pass\n",
    "            df = shuffle(df)\n",
    "            m_test=df[\"MAC\"]\n",
    "            del df[\"MAC\"]\n",
    "            X_test =df[df.columns[0:-1]]\n",
    "            X_test=np.array(X_test)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y_test=df[df.columns[-1]].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            results_y=[]\n",
    "            cv+=1\n",
    "            results_y.append(y_test)\n",
    "\n",
    "\n",
    "     \n",
    "   \n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "            second=time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_time=(float((time.time()-second)) )\n",
    "            second=time.time()\n",
    "            predict =clf.predict(X_test)\n",
    "            test_time=(float((time.time()-second)) )\n",
    "            if step==1:\n",
    "                altime=0\n",
    "                lines,class_based_results=score(altime,train_time,test_time,predict,y_test,class_based_results,i,cv,dname,ii)\n",
    "            else:\n",
    "                predict,altime=merged(m_test,predict,step,mixed)\n",
    "                lines,class_based_results=score(altime,train_time,test_time,predict,y_test,class_based_results,i,cv,dname,ii)\n",
    "            ths.write (lines)\n",
    "\n",
    "\n",
    "            df_cm = pd.DataFrame(confusion_matrix(y_test, predict))\n",
    "            if cm.empty:\n",
    "                cm =df_cm\n",
    "            else:\n",
    "                cm = cm.add(df_cm, fill_value=0)\n",
    "            \n",
    "        class_based_results=class_based_results/repetition\n",
    "        #print(class_based_results)\n",
    "        class_based_results.to_csv(\"class_based_results.csv\")\n",
    "        if False:\n",
    "            cm=cm//repetition\n",
    "            graph_name=output_csv+ii+\"_confusion matrix.pdf\"   \n",
    "            plt.figure(figsize = (40,28))\n",
    "            sns.heatmap(cm,xticklabels=target_names, yticklabels=target_names, annot=True, fmt='g')\n",
    "            plt.savefig(graph_name,bbox_inches='tight')#, dpi=400)\n",
    "            plt.show()\n",
    "            #print(cm)\n",
    "            print(\"\\n\\n\\n\")             \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    ths.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning applications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aalto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.592515400Z",
     "start_time": "2025-03-03T14:11:03.357597Z"
    }
   },
   "outputs": [],
   "source": [
    "feature= ['pck_size', 'Ether_type', 'LLC_ctrl', 'EAPOL_version', 'EAPOL_type', 'IP_ihl', 'IP_tos', 'IP_len', 'IP_flags', 'IP_DF', 'IP_ttl', 'IP_options', 'ICMP_code', 'TCP_dataofs', 'TCP_FIN', 'TCP_ACK', 'TCP_window', 'UDP_len', 'DHCP_options', 'BOOTP_hlen', 'BOOTP_flags', 'BOOTP_sname', 'BOOTP_file', 'BOOTP_options', 'DNS_qr', 'DNS_rd', 'DNS_qdcount', 'dport_class', 'payload_bytes', 'entropy',\n",
    "\"MAC\",\n",
    "'Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 调用 ML 函数\n",
    "# test='Aalto_test_IoTDevID_nilsimsa.csv'\n",
    "# train='Aalto_BIG_train_IoTDevID_nilsimsa.csv'\n",
    "# dataset=\"./Aalto_test/\"\n",
    "# step = 1\n",
    "# mixed = False\n",
    "# sayac = 2\n",
    "# output_csv = dataset+str(sayac)+\"_\"+str(step)+\"_\"+str(mixed)+\".csv\"\n",
    "# target_names = target_name(test)\n",
    "# ML(train, test, output_csv, feature, step, mixed, dataset[2:-1] + \"_\" + str(step))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T14:11:03.592515400Z",
     "start_time": "2025-03-03T14:11:03.370220900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT & NB & RF &  KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-03-03T14:11:03.374418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset         T   CV  ML alg  Acc   b_Acc Prec  Rec   F1       kap   tra-T    test-T  total   al-time \n"
     ]
    }
   ],
   "source": [
    "test='Aalto_test_IoTDevID.csv'\n",
    "train='Aalto_BIG_train_IoTDevID.csv'\n",
    "\n",
    "\n",
    "dataset=\"./Aalto/\"\n",
    "step=1\n",
    "\n",
    "\n",
    "mixed=True\n",
    "sayac=1\n",
    "output_csv=dataset+str(sayac)+\"_\"+str(step)+\"_\"+str(mixed)+\".csv\"\n",
    "target_names=target_name(test)\n",
    "ML(train,test,output_csv,feature,step,mixed,dataset[2:-1]+\"_\"+str(step))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM & GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ml_list={\"SVM\":SVC(C=10,gamma=1),\n",
    "         \"GB\":GradientBoostingClassifier(learning_rate=0.001,subsample=0.1,n_estimators=500,max_depth= 10,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test='Aalto_test_IoTDevID.csv'\n",
    "train='Aalto_BIG_train_IoTDevID.csv'\n",
    "\n",
    "\n",
    "\n",
    "dataset=\"./Aalto/\"\n",
    "step=1\n",
    "\n",
    "\n",
    "mixed=False\n",
    "sayac=2\n",
    "output_csv=dataset+str(sayac)+\"_\"+str(step)+\"_\"+str(mixed)+\"100_svm_gb.csv\"\n",
    "target_names=target_name(test)\n",
    "ML(train,test,output_csv,feature,step,mixed,dataset[2:-1]+\"_\"+str(step))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ml_list={\"GB\":GradientBoostingClassifier(learning_rate=0.001,subsample=0.1,n_estimators=500,max_depth= 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test='Aalto_test_IoTDevID.csv'\n",
    "train='Aalto_BIG_train_IoTDevID.csv'\n",
    "\n",
    "\n",
    "\n",
    "dataset=\"./Aalto/\"\n",
    "step=1\n",
    "\n",
    "\n",
    "mixed=False\n",
    "sayac=2\n",
    "output_csv=dataset+str(sayac)+\"_\"+str(step)+\"_\"+str(mixed)+\"100_svm_gb_GB.csv\"\n",
    "target_names=target_name(test)\n",
    "ML(train,test,output_csv,feature,step,mixed,dataset[2:-1]+\"_\"+str(step))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "test='Aalto_test_IoTDevID.csv'\n",
    "train='Aalto_BIG_train_IoTDevID.csv'\n",
    "\n",
    "\n",
    "\n",
    "dataset=\"./Aalto/\"\n",
    "step=1\n",
    "\n",
    "ml_list={\"MLP\":MLPClassifier(solver= 'adam', learning_rate= 'constant', hidden_layer_sizes= (1220, 1965), alpha= 0.1, activation= 'relu')}\n",
    "\n",
    "mixed=False\n",
    "sayac=2\n",
    "output_csv=dataset+str(sayac)+\"_\"+str(step)+\"_\"+str(mixed)+\"100_mlp.csv\"\n",
    "target_names=target_name(test)\n",
    "ML(train,test,output_csv,feature,step,mixed,dataset[2:-1]+\"_\"+str(step))   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
